{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "# from keras.layers import merge\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "# from keras.callbacks import History\n",
    "# from keras.layers import Activation\n",
    "# from keras.models import model_from_json\n",
    "# from keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import rotate as rot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from base_models import my_autoencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.load('images_dataset.npy')\n",
    "X_train = all_data[:2723, :]\n",
    "X_test = all_data[2723:, ]\n",
    "shape = X_train[0].shape # Get from dataset\n",
    "encoder, decoder = my_autoencode(shape, code_size=128)\n",
    "inp = k.layers.Input(shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "autoencoder = k.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer=\"adamax\", loss='mse')\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('hackathon_autoencoder.{epoch:02d}-{val_loss:.2f}.h5', verbose=1, save_best_only=True)\n",
    "]\n",
    "\n",
    "\n",
    "# If you want to resume from a checkpoint\n",
    "#     import keras.backend as K\n",
    "#     def reset_tf_session():\n",
    "#         K.clear_session()\n",
    "#         tf.reset_default_graph()\n",
    "#         s = K.get_session()\n",
    "#         return s\n",
    "#     #### uncomment below to continue training from model checkpoint\n",
    "#     #### every time epoch counter starts at 0, so you need to track epochs manually\n",
    "#     from keras.models import load_model\n",
    "#     s = reset_tf_session()\n",
    "#     autoencoder = load_model(\"checkpoints/hackathon_autoencoder.78-508.84.h5\")  # continue after epoch 0+1\n",
    "#     encoder = autoencoder.layers[1]\n",
    "#     decoder = autoencoder.layers[2]\n",
    "\n",
    "# # Train Model\n",
    "autoencoder.fit(x=X_train, y=X_train,\n",
    "                validation_data=[X_test, X_test],\n",
    "                epochs=2,\n",
    "                batch_size=4,\n",
    "                shuffle=True,\n",
    "                callbacks = callbacks\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
